services:
  liquid-labs-model-volume:
    container_name: liquid-labs-model-volume
    image: ${MODEL_IMAGE}
    networks:
      - liquid_labs_network

  liquid-labs-vllm:
    image: liquidai/liquid-labs-vllm:${STACK_VERSION}
    container_name: ${MODEL_NAME}
    command:
      - --model
      - /model
      - --port
      - "9000"
      - --max-logprobs
      - "0"
      - --dtype
      - bfloat16
      - --device
      - cuda
      - --enable-chunked-prefill
      - "False"
      - --tensor_parallel_size
      - "1"
      - --gpu-memory-utilization
      - "0.6"
      - --max-model-len
      - "1024"
      - --max-num-seqs
      - "750"
      - --max-seq-len-to-capture
      - "1024"
    depends_on:
      - liquid-labs-model-volume
    # This is equivalent to "runtime: nvidia", but does not require
    # the nvidia-container-runtime to be added in docker config.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes_from:
      - liquid-labs-model-volume
    networks:
      - liquid_labs_network

  liquid-labs-python-api:
    image: liquidai/liquid-labs-python-api:${STACK_VERSION}
    container_name: liquid-labs-python-api
    depends_on:
      - liquid-labs-vllm
    environment:
      # When ENV=production, http requests will be redirected to https
      - ENV=internal
      - IS_DOCKER=true
      - CONTAINER_PORT=9000
      - VLLM_IMAGE_NAME=liquidai/liquid-labs-vllm:${STACK_VERSION}
      - JWT_SECRET=${JWT_SECRET}
      - API_SECRET=${API_SECRET}
      - NVIDIA_VISIBLE_DEVICES=all
      - POSTGRES_SCHEMA=labs
      - DATABASE_URL=${DATABASE_URL}
    ports:
      - "8000:8000"
    networks:
      - liquid_labs_network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    # This is equivalent to "runtime: nvidia", but does not require
    # the nvidia-container-runtime to be added in docker config.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  liquid-labs-postgres:
    image: postgres:15
    container_name: liquid-labs-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_SCHEMA: ${POSTGRES_SCHEMA}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:5432"
    networks:
      - liquid_labs_network
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 5

  liquid-labs-web:
    image: liquidai/liquid-labs-web:${STACK_VERSION}
    container_name: liquid-labs-web
    depends_on:
      - liquid-labs-python-api
      - liquid-labs-postgres
    environment:
      - NEXT_PUBLIC_API_BASE_URL=http://liquid-labs-python-api:8000
      - API_SECRET=${API_SECRET}
      - AUTH_SECRET=${AUTH_SECRET}
      - JWT_SECRET=${JWT_SECRET}
      - NEXT_PUBLIC_DEPLOYMENT_MODE=on_prem
      - DATABASE_URL=${DATABASE_URL}
    networks:
      - liquid_labs_network
    ports:
      - "3000:3000"

networks:
  liquid_labs_network:
    name: liquid_labs_network
    driver: bridge

volumes:
  postgres_data:
    external: true
